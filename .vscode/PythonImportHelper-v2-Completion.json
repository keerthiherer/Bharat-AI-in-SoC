[
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "json,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json.",
        "description": "json.",
        "detail": "json.",
        "documentation": {}
    },
    {
        "label": "TfidfVectorizer",
        "importPath": "sklearn.feature_extraction.text",
        "description": "sklearn.feature_extraction.text",
        "isExtraImport": true,
        "detail": "sklearn.feature_extraction.text",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "listen_loop",
        "importPath": "wake_vosk",
        "description": "wake_vosk",
        "isExtraImport": true,
        "detail": "wake_vosk",
        "documentation": {}
    },
    {
        "label": "listen_loop",
        "importPath": "wake_vosk",
        "description": "wake_vosk",
        "isExtraImport": true,
        "detail": "wake_vosk",
        "documentation": {}
    },
    {
        "label": "listen_for_wake",
        "importPath": "wake_fast",
        "description": "wake_fast",
        "isExtraImport": true,
        "detail": "wake_fast",
        "documentation": {}
    },
    {
        "label": "system_info",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "system_info",
        "description": "system_info",
        "detail": "system_info",
        "documentation": {}
    },
    {
        "label": "speak",
        "importPath": "tts_piper",
        "description": "tts_piper",
        "isExtraImport": true,
        "detail": "tts_piper",
        "documentation": {}
    },
    {
        "label": "Llama",
        "importPath": "llama_cpp",
        "description": "llama_cpp",
        "isExtraImport": true,
        "detail": "llama_cpp",
        "documentation": {}
    },
    {
        "label": "nlu",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "nlu",
        "description": "nlu",
        "detail": "nlu",
        "documentation": {}
    },
    {
        "label": "KnowledgeBase",
        "importPath": "knowledge_base",
        "description": "knowledge_base",
        "isExtraImport": true,
        "detail": "knowledge_base",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "psutil,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "psutil.",
        "description": "psutil.",
        "detail": "psutil.",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "wave",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "wave",
        "description": "wave",
        "detail": "wave",
        "documentation": {}
    },
    {
        "label": "PiperVoice",
        "importPath": "piper",
        "description": "piper",
        "isExtraImport": true,
        "detail": "piper",
        "documentation": {}
    },
    {
        "label": "SynthesisConfig",
        "importPath": "piper.voice",
        "description": "piper.voice",
        "isExtraImport": true,
        "detail": "piper.voice",
        "documentation": {}
    },
    {
        "label": "get_intent",
        "importPath": "intent_predict",
        "description": "intent_predict",
        "isExtraImport": true,
        "detail": "intent_predict",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "pyaudio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pyaudio",
        "description": "pyaudio",
        "detail": "pyaudio",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "vosk",
        "description": "vosk",
        "isExtraImport": true,
        "detail": "vosk",
        "documentation": {}
    },
    {
        "label": "KaldiRecognizer",
        "importPath": "vosk",
        "description": "vosk",
        "isExtraImport": true,
        "detail": "vosk",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "vosk",
        "description": "vosk",
        "isExtraImport": true,
        "detail": "vosk",
        "documentation": {}
    },
    {
        "label": "KaldiRecognizer",
        "importPath": "vosk",
        "description": "vosk",
        "isExtraImport": true,
        "detail": "vosk",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "WAKE_WORDS",
        "kind": 5,
        "importPath": "config",
        "description": "config",
        "peekOfCode": "WAKE_WORDS = [\n    \"ira\", \"vira\", \"वीरा\",     # Ira (Vira)\n    \"aiva\", \"ava\", \"ऐवा\",      # Aiva\n    \"ziva\", \"ज़ीवा\",           # Ziva\n    \"kiva\", \"कीवा\",            # Kiva\n    \"tiva\", \"टीवा\",            # Tiva\n    \"reva\", \"रेवा\",            # Reva\n    \"niva\", \"नीवा\"             # Niva\n]\n# Audio Noise Threshold",
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "NOISE_THRESHOLD",
        "kind": 5,
        "importPath": "config",
        "description": "config",
        "peekOfCode": "NOISE_THRESHOLD = 800\n# Messages\nMSG_CAMERA_NOT_FOUND = \"कौई कैमरा नहीं मिला\"  # No camera found\nMSG_CAMERA_OPENING = \"कैमरा खोल रहा हूँ\"      # Opening camera\nMSG_PHOTO_MODE = \"फोटो लेने के लिए कैमरा खोल रहा हूँ\"\nMSG_VIDEO_MODE = \"वीडियो रिकॉर्डिंग के लिए कैमरा खोल रहा हूँ\"",
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "MSG_CAMERA_NOT_FOUND",
        "kind": 5,
        "importPath": "config",
        "description": "config",
        "peekOfCode": "MSG_CAMERA_NOT_FOUND = \"कौई कैमरा नहीं मिला\"  # No camera found\nMSG_CAMERA_OPENING = \"कैमरा खोल रहा हूँ\"      # Opening camera\nMSG_PHOTO_MODE = \"फोटो लेने के लिए कैमरा खोल रहा हूँ\"\nMSG_VIDEO_MODE = \"वीडियो रिकॉर्डिंग के लिए कैमरा खोल रहा हूँ\"",
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "MSG_CAMERA_OPENING",
        "kind": 5,
        "importPath": "config",
        "description": "config",
        "peekOfCode": "MSG_CAMERA_OPENING = \"कैमरा खोल रहा हूँ\"      # Opening camera\nMSG_PHOTO_MODE = \"फोटो लेने के लिए कैमरा खोल रहा हूँ\"\nMSG_VIDEO_MODE = \"वीडियो रिकॉर्डिंग के लिए कैमरा खोल रहा हूँ\"",
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "MSG_PHOTO_MODE",
        "kind": 5,
        "importPath": "config",
        "description": "config",
        "peekOfCode": "MSG_PHOTO_MODE = \"फोटो लेने के लिए कैमरा खोल रहा हूँ\"\nMSG_VIDEO_MODE = \"वीडियो रिकॉर्डिंग के लिए कैमरा खोल रहा हूँ\"",
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "MSG_VIDEO_MODE",
        "kind": 5,
        "importPath": "config",
        "description": "config",
        "peekOfCode": "MSG_VIDEO_MODE = \"वीडियो रिकॉर्डिंग के लिए कैमरा खोल रहा हूँ\"",
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "history_kb",
        "kind": 5,
        "importPath": "create_knowledge_base",
        "description": "create_knowledge_base",
        "peekOfCode": "history_kb = {\n    \"शब्द\": \"परिभाषा\",\n    \"इतिहास\": \"अतीत की घटनाओं और मानव सभ्यता का अध्ययन\",\n    \"प्राचीन भारत\": \"भारत का वह काल जो मुख्यतः 5वीं शताब्दी ईसा पूर्व से 12वीं शताब्दी ईस्वी तक माना जाता है\",\n    \"मध्यकालीन भारत\": \"भारत का वह काल जो 12वीं शताब्दी से 18वीं शताब्दी तक माना जाता है\",\n    \"आधुनिक भारत\": \"भारत का वह काल जो 18वीं शताब्दी से आज तक है\",\n    \"मौर्य साम्राज्य\": \"चंद्रगुप्त मौर्य द्वारा स्थापित एक महान भारतीय साम्राज्य, जिसका विस्तार सम्पूर्ण भारत में था\",\n    \"गुप्त साम्राज्य\": \"चंद्रगुप्त प्रथम द्वारा स्थापित एक शक्तिशाली साम्राज्य, जिसे भारतीय इतिहास का स्वर्ण युग कहा जाता है\",\n    \"अशोक\": \"मौर्य साम्राज्य का महानतम सम्राट, जिसने बौद्ध धर्म अपनाया और भारत को एकता से बांधा\",\n    \"अकबर\": \"मुगल साम्राज्य का सबसे प्रभावशाली और दूरदर्शी सम्राट\",",
        "detail": "create_knowledge_base",
        "documentation": {}
    },
    {
        "label": "indian_history_kb",
        "kind": 5,
        "importPath": "create_knowledge_base",
        "description": "create_knowledge_base",
        "peekOfCode": "indian_history_kb = {\n    \"भारतीय इतिहास\": \"भारत देश के अतीत की घटनाओं का विस्तृत विवरण\",\n    \"आर्य\": \"प्राचीन भारत में आने वाली एक जाति\",\n    \"वेद\": \"हिंदू धर्म के प्राचीनतम धार्मिक ग्रंथ\",\n    \"ऋग्वेद\": \"चार वेदों में सबसे प्राचीन वेद\",\n    \"महाभारत\": \"भारत का सबसे बड़ा महाकाव्य\",\n    \"रामायण\": \"संस्कृत का प्राचीन महाकाव्य\",\n    \"बुद्ध\": \"बौद्ध धर्म के संस्थापक\",\n    \"महावीर\": \"जैन धर्म के 24वें तीर्थंकर\",\n    \"राजस्थान\": \"भारत का पश्चिमी राज्य, जो अपनी सांस्कृतिक विरासत के लिए प्रसिद्ध है\",",
        "detail": "create_knowledge_base",
        "documentation": {}
    },
    {
        "label": "politics_kb",
        "kind": 5,
        "importPath": "create_knowledge_base",
        "description": "create_knowledge_base",
        "peekOfCode": "politics_kb = {\n    \"राजनीति\": \"सरकार, नीतियों और शासन से संबंधित विषय\",\n    \"संविधान\": \"भारत का सर्वोच्च कानून, जो सभी नियमों को परिभाषित करता है\",\n    \"संसद\": \"भारत की सर्वोच्च विधायिका\",\n    \"लोकसभा\": \"भारत की निम्न सदन, जिसमें जनता के प्रतिनिधि होते हैं\",\n    \"राज्यसभा\": \"भारत की उच्च सदन\",\n    \"मुख्य मंत्री\": \"किसी राज्य का प्रमुख मंत्री\",\n    \"राष्ट्रपति\": \"भारत का राष्ट्र प्रमुख\",\n    \"प्रधान मंत्री\": \"भारत का सरकार प्रमुख\",\n    \"चुनाव\": \"लोकतांत्रिक प्रक्रिया जिसके माध्यम से जनता अपने प्रतिनिधि चुनती है\",",
        "detail": "create_knowledge_base",
        "documentation": {}
    },
    {
        "label": "world_gk_kb",
        "kind": 5,
        "importPath": "create_knowledge_base",
        "description": "create_knowledge_base",
        "peekOfCode": "world_gk_kb = {\n    \"विश्व\": \"पृथ्वी और उस पर रहने वाली सभी सभ्यताएं\",\n    \"अमेरिका\": \"विश्व की सबसे शक्तिशाली अर्थव्यवस्था वाला देश\",\n    \"यूरोप\": \"विश्व का एक महाद्वीप\",\n    \"एशिया\": \"विश्व का सबसे बड़ा महाद्वीप\",\n    \"अफ्रीका\": \"विश्व का दूसरा सबसे बड़ा महाद्वीप\",\n    \"ऑस्ट्रेलिया\": \"विश्व का सबसे छोटा महाद्वीप\",\n    \"दक्षिण अमेरिका\": \"अमेरिका महाद्वीप का दक्षिणी भाग\",\n    \"संयुक्त राष्ट्र\": \"विश्व का एक अंतर्राष्ट्रीय संगठन\",\n    \"नोबेल पुरस्कार\": \"विश्व का सबसे प्रतिष्ठित पुरस्कार\",",
        "detail": "create_knowledge_base",
        "documentation": {}
    },
    {
        "label": "india_gk_kb",
        "kind": 5,
        "importPath": "create_knowledge_base",
        "description": "create_knowledge_base",
        "peekOfCode": "india_gk_kb = {\n    \"भारत\": \"दक्षिण एशिया का एक देश, जो विविधता में एकता के लिए प्रसिद्ध है\",\n    \"भारत की राजधानी\": \"नई दिल्ली\",\n    \"राष्ट्रगान\": \"जन गण मन, जो रवीन्द्रनाथ टैगोर द्वारा रचित है\",\n    \"राष्ट्रगीत\": \"वंदे मातरम्\",\n    \"राष्ट्रचिह्न\": \"अशोक स्तंभ\",\n    \"राष्ट्रध्वज\": \"भारत का तिरंगा झंडा\",\n    \"भारतीय संविधान\": \"भारत का सर्वोच्च कानून\",\n    \"भारत के राज्य\": \"भारत में 28 राज्य और 8 केंद्र शासित प्रदेश हैं\",\n    \"आबादी\": \"भारत विश्व का दूसरा सबसे अधिक जनसंख्या वाला देश है\",",
        "detail": "create_knowledge_base",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "intent_model",
        "description": "intent_model",
        "peekOfCode": "data = json.load(open(\"intent.json\", encoding=\"utf-8\"))\nX, y = [], []\nfor intent in data[\"intents\"]:\n    for p in intent[\"patterns\"]:\n        X.append(p)\n        y.append(intent[\"tag\"])\nvectorizer = TfidfVectorizer()\nXv = vectorizer.fit_transform(X)\nmodel = LogisticRegression()\nmodel.fit(Xv, y)",
        "detail": "intent_model",
        "documentation": {}
    },
    {
        "label": "vectorizer",
        "kind": 5,
        "importPath": "intent_model",
        "description": "intent_model",
        "peekOfCode": "vectorizer = TfidfVectorizer()\nXv = vectorizer.fit_transform(X)\nmodel = LogisticRegression()\nmodel.fit(Xv, y)\npickle.dump(model, open(\"intent_model.pkl\", \"wb\"))\npickle.dump(vectorizer, open(\"vectorizer.pkl\", \"wb\"))\nprint(\"✅ Intent model trained\")",
        "detail": "intent_model",
        "documentation": {}
    },
    {
        "label": "Xv",
        "kind": 5,
        "importPath": "intent_model",
        "description": "intent_model",
        "peekOfCode": "Xv = vectorizer.fit_transform(X)\nmodel = LogisticRegression()\nmodel.fit(Xv, y)\npickle.dump(model, open(\"intent_model.pkl\", \"wb\"))\npickle.dump(vectorizer, open(\"vectorizer.pkl\", \"wb\"))\nprint(\"✅ Intent model trained\")",
        "detail": "intent_model",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "intent_model",
        "description": "intent_model",
        "peekOfCode": "model = LogisticRegression()\nmodel.fit(Xv, y)\npickle.dump(model, open(\"intent_model.pkl\", \"wb\"))\npickle.dump(vectorizer, open(\"vectorizer.pkl\", \"wb\"))\nprint(\"✅ Intent model trained\")",
        "detail": "intent_model",
        "documentation": {}
    },
    {
        "label": "get_intent",
        "kind": 2,
        "importPath": "intent_predict",
        "description": "intent_predict",
        "peekOfCode": "def get_intent(text):\n    if not MODEL_LOADED:\n        return None, 0.0\n    try:\n        # Vectorize input\n        Xv = vectorizer.transform([text])\n        # Predict\n        probabilities = model.predict_proba(Xv)[0]\n        max_idx = np.argmax(probabilities)\n        confidence = probabilities[max_idx]",
        "detail": "intent_predict",
        "documentation": {}
    },
    {
        "label": "KnowledgeBase",
        "kind": 6,
        "importPath": "knowledge_base",
        "description": "knowledge_base",
        "peekOfCode": "class KnowledgeBase:\n    def __init__(self):\n        \"\"\"Load all knowledge base files\"\"\"\n        self.history = self._load_kb(\"history_kb.pkl\")\n        self.indian_history = self._load_kb(\"indian_history_kb.pkl\")\n        self.politics = self._load_kb(\"politics_kb.pkl\")\n        self.world_gk = self._load_kb(\"world_gk_kb.pkl\")\n        self.india_gk = self._load_kb(\"india_gk_kb.pkl\")\n    def _load_kb(self, filename):\n        \"\"\"Load pickle file\"\"\"",
        "detail": "knowledge_base",
        "documentation": {}
    },
    {
        "label": "predict_intent",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def predict_intent(text):\n    X = vectorizer.transform([text])\n    intent = intent_model.predict(X)[0]\n    confidence = max(intent_model.predict_proba(X)[0])\n    return intent, confidence\n# =========================================\n# Load RAG\n# =========================================\n#rag = SimpleRAG(\"rag.jsonl\")\n# =========================================",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "qwen_reply",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def qwen_reply(hindi_text):\n    prompt = f\"\"\"आप एक हिंदी वॉयस असिस्टेंट हैं।\nसंक्षेप में उत्तर दें।\nUser: {hindi_text}\nAssistant:\"\"\"\n    result = llm(\n        prompt=prompt,\n        max_tokens=64,\n        temperature=0.6,\n        top_p=0.9,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "intent_model",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "intent_model = pickle.load(open(\"intent_model.pkl\", \"rb\"))\nvectorizer = pickle.load(open(\"vectorizer.pkl\", \"rb\"))\n# [NEW] Load Deterministic Intents\nintent_map = nlu.load_intents(\"intent.json\")\nprint(f\"Loaded {len(intent_map)} deterministic keywords\")\n# [NEW] Load Knowledge Base\nkb = KnowledgeBase()\nprint(\"✅ Knowledge Base loaded\")\ndef predict_intent(text):\n    X = vectorizer.transform([text])",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "vectorizer",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "vectorizer = pickle.load(open(\"vectorizer.pkl\", \"rb\"))\n# [NEW] Load Deterministic Intents\nintent_map = nlu.load_intents(\"intent.json\")\nprint(f\"Loaded {len(intent_map)} deterministic keywords\")\n# [NEW] Load Knowledge Base\nkb = KnowledgeBase()\nprint(\"✅ Knowledge Base loaded\")\ndef predict_intent(text):\n    X = vectorizer.transform([text])\n    intent = intent_model.predict(X)[0]",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "intent_map",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "intent_map = nlu.load_intents(\"intent.json\")\nprint(f\"Loaded {len(intent_map)} deterministic keywords\")\n# [NEW] Load Knowledge Base\nkb = KnowledgeBase()\nprint(\"✅ Knowledge Base loaded\")\ndef predict_intent(text):\n    X = vectorizer.transform([text])\n    intent = intent_model.predict(X)[0]\n    confidence = max(intent_model.predict_proba(X)[0])\n    return intent, confidence",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "kb",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "kb = KnowledgeBase()\nprint(\"✅ Knowledge Base loaded\")\ndef predict_intent(text):\n    X = vectorizer.transform([text])\n    intent = intent_model.predict(X)[0]\n    confidence = max(intent_model.predict_proba(X)[0])\n    return intent, confidence\n# =========================================\n# Load RAG\n# =========================================",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "#rag",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "#rag = SimpleRAG(\"rag.jsonl\")\n# =========================================\n# Load Qwen ONCE\n# =========================================\nMODEL_PATH = \"Llama-3.2-1B-Instruct-Q4_K_M.gguf\"\nprint(\"Loading llama model...\")\nllm = Llama(\n    model_path=MODEL_PATH,\n    n_ctx=128,\n    n_threads=4,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "MODEL_PATH",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "MODEL_PATH = \"Llama-3.2-1B-Instruct-Q4_K_M.gguf\"\nprint(\"Loading llama model...\")\nllm = Llama(\n    model_path=MODEL_PATH,\n    n_ctx=128,\n    n_threads=4,\n    n_batch=64,\n    verbose=False\n)\nprint(\"Qwen ready ✅\")",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "llm",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "llm = Llama(\n    model_path=MODEL_PATH,\n    n_ctx=128,\n    n_threads=4,\n    n_batch=64,\n    verbose=False\n)\nprint(\"Qwen ready ✅\")\n# =========================================\n# Qwen fallback",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "load_intents",
        "kind": 2,
        "importPath": "nlu",
        "description": "nlu",
        "peekOfCode": "def load_intents(json_path):\n    \"\"\"\n    Loads intents from JSON and creates a mapping of word -> intent_tag.\n    \"\"\"\n    try:\n        with open(json_path, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n        intent_map = {}\n        for intent in data['intents']:\n            tag = intent['tag']",
        "detail": "nlu",
        "documentation": {}
    },
    {
        "label": "preprocess",
        "kind": 2,
        "importPath": "nlu",
        "description": "nlu",
        "peekOfCode": "def preprocess(text):\n    \"\"\"\n    Lowercase, remove punctuation, strip whitespace.\n    \"\"\"\n    if not isinstance(text, str):\n        return \"\"\n    text = text.lower()\n    # Remove punctuation using translation table\n    # Include common English and Hindi punctuation keys if needed, but standard string.punctuation handles standard ASCII\n    text = text.translate(str.maketrans('', '', string.punctuation))",
        "detail": "nlu",
        "documentation": {}
    },
    {
        "label": "tokenize",
        "kind": 2,
        "importPath": "nlu",
        "description": "nlu",
        "peekOfCode": "def tokenize(text):\n    \"\"\"\n    Split by whitespace.\n    \"\"\"\n    return text.split()\ndef filter_noise(tokens):\n    \"\"\"\n    Remove stopwords and short words.\n    \"\"\"\n    STOPWORDS = {",
        "detail": "nlu",
        "documentation": {}
    },
    {
        "label": "filter_noise",
        "kind": 2,
        "importPath": "nlu",
        "description": "nlu",
        "peekOfCode": "def filter_noise(tokens):\n    \"\"\"\n    Remove stopwords and short words.\n    \"\"\"\n    STOPWORDS = {\n        # Romanized\n        \"hai\", \"h\", \"ko\", \"se\", \"ka\", \"ki\", \"ke\", \"me\", \"mein\", \n        \"aur\", \"tathaa\", \"evam\", \"kyon\", \"kya\", \"kab\", \"kaise\", \n        \"kahan\", \"jab\", \"tab\", \"ab\", \"abhi\", \"bhi\", \"toh\", \"hi\", \n        \"ji\", \"sir\", \"madam\", \"sunie\", \"suno\", \"hey\", \"hello\", \"hi\", ",
        "detail": "nlu",
        "documentation": {}
    },
    {
        "label": "get_levenshtein_distance",
        "kind": 2,
        "importPath": "nlu",
        "description": "nlu",
        "peekOfCode": "def get_levenshtein_distance(s1, s2):\n    if len(s1) < len(s2):\n        return get_levenshtein_distance(s2, s1)\n    if len(s2) == 0:\n        return len(s1)\n    previous_row = range(len(s2) + 1)\n    for i, c1 in enumerate(s1):\n        current_row = [i + 1]\n        for j, c2 in enumerate(s2):\n            insertions = previous_row[j + 1] + 1",
        "detail": "nlu",
        "documentation": {}
    },
    {
        "label": "detect_intent",
        "kind": 2,
        "importPath": "nlu",
        "description": "nlu",
        "peekOfCode": "def detect_intent(text, intent_map):\n    \"\"\"\n    1. Preprocess & Tokenize\n    2. Filter Noise\n    3. Match (Exact then Fuzzy)\n    \"\"\"\n    clean_text = preprocess(text)\n    tokens = tokenize(clean_text)\n    clean_tokens = filter_noise(tokens)\n    # 1. Exact Match",
        "detail": "nlu",
        "documentation": {}
    },
    {
        "label": "fallback_to_llm",
        "kind": 2,
        "importPath": "nlu",
        "description": "nlu",
        "peekOfCode": "def fallback_to_llm(text):\n    \"\"\"\n    Generate a concise response using the LLM.\n    \"\"\"\n    prompt = f\"\"\"\n    आप एक हिंदी वॉयस असिस्टेंट हैं।\n    कृपया केवल उपयोगकर्ता के प्रश्न का उत्तर दें।\n    किसी भी उपयोगकर्ता या सहायक लेबल का उपयोग न करें।\n    {text}\n    \"\"\"",
        "detail": "nlu",
        "documentation": {}
    },
    {
        "label": "time_now",
        "kind": 2,
        "importPath": "system_info",
        "description": "system_info",
        "peekOfCode": "def time_now(): return datetime.datetime.now().strftime(\"%H:%M:%S\")\ndef date_today(): return datetime.date.today().strftime(\"%d %B %Y\")\ndef day_today(): return datetime.datetime.now().strftime(\"%A\")\ndef uptime(): return str(datetime.datetime.now() -\n                        datetime.datetime.fromtimestamp(psutil.boot_time())).split('.')[0]\ndef cpu(): return f\"{psutil.cpu_percent()} %\"\ndef ram(): return f\"{psutil.virtual_memory().percent} %\"\ndef disk(): return f\"{psutil.disk_usage('/').percent} %\"\ndef battery():\n    b = psutil.sensors_battery()",
        "detail": "system_info",
        "documentation": {}
    },
    {
        "label": "date_today",
        "kind": 2,
        "importPath": "system_info",
        "description": "system_info",
        "peekOfCode": "def date_today(): return datetime.date.today().strftime(\"%d %B %Y\")\ndef day_today(): return datetime.datetime.now().strftime(\"%A\")\ndef uptime(): return str(datetime.datetime.now() -\n                        datetime.datetime.fromtimestamp(psutil.boot_time())).split('.')[0]\ndef cpu(): return f\"{psutil.cpu_percent()} %\"\ndef ram(): return f\"{psutil.virtual_memory().percent} %\"\ndef disk(): return f\"{psutil.disk_usage('/').percent} %\"\ndef battery():\n    b = psutil.sensors_battery()\n    return f\"{b.percent} %\" if b else \"उपलब्ध नहीं\"",
        "detail": "system_info",
        "documentation": {}
    },
    {
        "label": "day_today",
        "kind": 2,
        "importPath": "system_info",
        "description": "system_info",
        "peekOfCode": "def day_today(): return datetime.datetime.now().strftime(\"%A\")\ndef uptime(): return str(datetime.datetime.now() -\n                        datetime.datetime.fromtimestamp(psutil.boot_time())).split('.')[0]\ndef cpu(): return f\"{psutil.cpu_percent()} %\"\ndef ram(): return f\"{psutil.virtual_memory().percent} %\"\ndef disk(): return f\"{psutil.disk_usage('/').percent} %\"\ndef battery():\n    b = psutil.sensors_battery()\n    return f\"{b.percent} %\" if b else \"उपलब्ध नहीं\"\ndef temp():",
        "detail": "system_info",
        "documentation": {}
    },
    {
        "label": "uptime",
        "kind": 2,
        "importPath": "system_info",
        "description": "system_info",
        "peekOfCode": "def uptime(): return str(datetime.datetime.now() -\n                        datetime.datetime.fromtimestamp(psutil.boot_time())).split('.')[0]\ndef cpu(): return f\"{psutil.cpu_percent()} %\"\ndef ram(): return f\"{psutil.virtual_memory().percent} %\"\ndef disk(): return f\"{psutil.disk_usage('/').percent} %\"\ndef battery():\n    b = psutil.sensors_battery()\n    return f\"{b.percent} %\" if b else \"उपलब्ध नहीं\"\ndef temp():\n    try:",
        "detail": "system_info",
        "documentation": {}
    },
    {
        "label": "cpu",
        "kind": 2,
        "importPath": "system_info",
        "description": "system_info",
        "peekOfCode": "def cpu(): return f\"{psutil.cpu_percent()} %\"\ndef ram(): return f\"{psutil.virtual_memory().percent} %\"\ndef disk(): return f\"{psutil.disk_usage('/').percent} %\"\ndef battery():\n    b = psutil.sensors_battery()\n    return f\"{b.percent} %\" if b else \"उपलब्ध नहीं\"\ndef temp():\n    try:\n        return f\"{list(psutil.sensors_temperatures().values())[0][0].current} °C\"\n    except:",
        "detail": "system_info",
        "documentation": {}
    },
    {
        "label": "ram",
        "kind": 2,
        "importPath": "system_info",
        "description": "system_info",
        "peekOfCode": "def ram(): return f\"{psutil.virtual_memory().percent} %\"\ndef disk(): return f\"{psutil.disk_usage('/').percent} %\"\ndef battery():\n    b = psutil.sensors_battery()\n    return f\"{b.percent} %\" if b else \"उपलब्ध नहीं\"\ndef temp():\n    try:\n        return f\"{list(psutil.sensors_temperatures().values())[0][0].current} °C\"\n    except:\n        return \"उपलब्ध नहीं\"",
        "detail": "system_info",
        "documentation": {}
    },
    {
        "label": "disk",
        "kind": 2,
        "importPath": "system_info",
        "description": "system_info",
        "peekOfCode": "def disk(): return f\"{psutil.disk_usage('/').percent} %\"\ndef battery():\n    b = psutil.sensors_battery()\n    return f\"{b.percent} %\" if b else \"उपलब्ध नहीं\"\ndef temp():\n    try:\n        return f\"{list(psutil.sensors_temperatures().values())[0][0].current} °C\"\n    except:\n        return \"उपलब्ध नहीं\"\ndef network():",
        "detail": "system_info",
        "documentation": {}
    },
    {
        "label": "battery",
        "kind": 2,
        "importPath": "system_info",
        "description": "system_info",
        "peekOfCode": "def battery():\n    b = psutil.sensors_battery()\n    return f\"{b.percent} %\" if b else \"उपलब्ध नहीं\"\ndef temp():\n    try:\n        return f\"{list(psutil.sensors_temperatures().values())[0][0].current} °C\"\n    except:\n        return \"उपलब्ध नहीं\"\ndef network():\n    try:",
        "detail": "system_info",
        "documentation": {}
    },
    {
        "label": "temp",
        "kind": 2,
        "importPath": "system_info",
        "description": "system_info",
        "peekOfCode": "def temp():\n    try:\n        return f\"{list(psutil.sensors_temperatures().values())[0][0].current} °C\"\n    except:\n        return \"उपलब्ध नहीं\"\ndef network():\n    try:\n        socket.create_connection((\"8.8.8.8\", 53), timeout=2)\n        return \"इंटरनेट चालू है\"\n    except:",
        "detail": "system_info",
        "documentation": {}
    },
    {
        "label": "network",
        "kind": 2,
        "importPath": "system_info",
        "description": "system_info",
        "peekOfCode": "def network():\n    try:\n        socket.create_connection((\"8.8.8.8\", 53), timeout=2)\n        return \"इंटरनेट चालू है\"\n    except:\n        return \"इंटरनेट बंद है\"\ndef ip(): return socket.gethostbyname(socket.gethostname())\ndef hostname(): return socket.gethostname()",
        "detail": "system_info",
        "documentation": {}
    },
    {
        "label": "ip",
        "kind": 2,
        "importPath": "system_info",
        "description": "system_info",
        "peekOfCode": "def ip(): return socket.gethostbyname(socket.gethostname())\ndef hostname(): return socket.gethostname()",
        "detail": "system_info",
        "documentation": {}
    },
    {
        "label": "hostname",
        "kind": 2,
        "importPath": "system_info",
        "description": "system_info",
        "peekOfCode": "def hostname(): return socket.gethostname()",
        "detail": "system_info",
        "documentation": {}
    },
    {
        "label": "intent_map",
        "kind": 5,
        "importPath": "test_nlu",
        "description": "test_nlu",
        "peekOfCode": "intent_map = nlu.load_intents(\"intent.json\")\nprint(f\"Loaded {len(intent_map)} keywords.\")\n# Test inputs (Romanized examples from user + Devanagari actuals)\ntest_inputs = [\n    (\"asdh din\", None),          # mismatch (Roman 'din' vs Devanagari 'दिन')\n    (\"asdh दिन\", \"day\"),         # Correct Hindi input\n    (\"दिन बताओ\", \"day\"),         # \"batao\" is stopword, \"din\" matches\n    (\"random noise\", None),\n    (\"kuchhsh din\", None),       # Roman mismatch\n    (\"कुछश दिन\", \"day\"),         # Devanagari noise + match",
        "detail": "test_nlu",
        "documentation": {}
    },
    {
        "label": "test_inputs",
        "kind": 5,
        "importPath": "test_nlu",
        "description": "test_nlu",
        "peekOfCode": "test_inputs = [\n    (\"asdh din\", None),          # mismatch (Roman 'din' vs Devanagari 'दिन')\n    (\"asdh दिन\", \"day\"),         # Correct Hindi input\n    (\"दिन बताओ\", \"day\"),         # \"batao\" is stopword, \"din\" matches\n    (\"random noise\", None),\n    (\"kuchhsh din\", None),       # Roman mismatch\n    (\"कुछश दिन\", \"day\"),         # Devanagari noise + match\n    (\"समय\", \"time\"),\n    (\"बंद करो\", \"exit\"),         # \"karo\" stopword, \"band\" (बंद) matches\n]",
        "detail": "test_nlu",
        "documentation": {}
    },
    {
        "label": "speak",
        "kind": 2,
        "importPath": "tts_piper",
        "description": "tts_piper",
        "peekOfCode": "def speak(text):\n    if not text or not text.strip():\n        return\n    if voice is None:\n        print(\"ERROR: Piper voice model not loaded\")\n        return\n    try:\n        print(\"Speaking text...\")\n    except UnicodeEncodeError:\n        print(\"Speaking text (Unicode)\")",
        "detail": "tts_piper",
        "documentation": {}
    },
    {
        "label": "PIPER_MODEL",
        "kind": 5,
        "importPath": "tts_piper",
        "description": "tts_piper",
        "peekOfCode": "PIPER_MODEL = \"piper/hi_IN-priyamvada-medium.onnx\"\n# Load the voice model once at module level for better performance\ntry:\n    voice = PiperVoice.load(PIPER_MODEL)\n    print(\"Piper voice model loaded successfully\")\nexcept Exception as e:\n    print(f\"Error loading Piper voice model: {e}\")\n    voice = None\ndef speak(text):\n    if not text or not text.strip():",
        "detail": "tts_piper",
        "documentation": {}
    },
    {
        "label": "test_phrases",
        "kind": 5,
        "importPath": "verify_intent",
        "description": "verify_intent",
        "peekOfCode": "test_phrases = [\n    \"aiva\",\n    \"hey aiva\",\n    \"hello aiva\",\n    \"what is time\",\n    \"open camera\",\n    \"random noise\",\n    \"aiva listen\"\n]\nprint(\"Testing Intent Model Prediction:\\n\")",
        "detail": "verify_intent",
        "documentation": {}
    },
    {
        "label": "detect_wake",
        "kind": 2,
        "importPath": "wake_fast",
        "description": "wake_fast",
        "peekOfCode": "def detect_wake(recognizer, data):\n    # Accept returns True if a full silence/end of utterance is reached\n    # but we are interested in partials for speed\n    if recognizer.AcceptWaveform(data):\n        result = json.loads(recognizer.Result())\n        text = result.get(\"text\", \"\")\n    else:\n        # PartialResult gives us real-time hypothesis\n        partial = recognizer.PartialResult()\n        text = json.loads(partial).get(\"partial\", \"\")",
        "detail": "wake_fast",
        "documentation": {}
    },
    {
        "label": "listen_for_wake",
        "kind": 2,
        "importPath": "wake_fast",
        "description": "wake_fast",
        "peekOfCode": "def listen_for_wake():\n    if not rec:\n        return False\n    p = pyaudio.PyAudio()\n    stream = p.open(\n        format=pyaudio.paInt16,\n        channels=1,\n        rate=SAMPLE_RATE,\n        input=True,\n        frames_per_buffer=BLOCK_SIZE",
        "detail": "wake_fast",
        "documentation": {}
    },
    {
        "label": "WAKE_WORDS",
        "kind": 5,
        "importPath": "wake_fast",
        "description": "wake_fast",
        "peekOfCode": "WAKE_WORDS = [\"इवा\", \"iva\", \"kira\", \"ava\", \"hyva\", \"hey nova\", \"hey\"]  # check multiple\nMODEL_PATH = \"vosk-model-small-hi-0.22\"\nSAMPLE_RATE = 16000\nBLOCK_SIZE = 1024   # fast\n# =========================================\n# Load Vosk model\n# =========================================\ntry:\n    model = Model(MODEL_PATH)\n    rec = KaldiRecognizer(model, SAMPLE_RATE)",
        "detail": "wake_fast",
        "documentation": {}
    },
    {
        "label": "MODEL_PATH",
        "kind": 5,
        "importPath": "wake_fast",
        "description": "wake_fast",
        "peekOfCode": "MODEL_PATH = \"vosk-model-small-hi-0.22\"\nSAMPLE_RATE = 16000\nBLOCK_SIZE = 1024   # fast\n# =========================================\n# Load Vosk model\n# =========================================\ntry:\n    model = Model(MODEL_PATH)\n    rec = KaldiRecognizer(model, SAMPLE_RATE)\n    print(\"✅ Vosk (Fast) model loaded\")",
        "detail": "wake_fast",
        "documentation": {}
    },
    {
        "label": "SAMPLE_RATE",
        "kind": 5,
        "importPath": "wake_fast",
        "description": "wake_fast",
        "peekOfCode": "SAMPLE_RATE = 16000\nBLOCK_SIZE = 1024   # fast\n# =========================================\n# Load Vosk model\n# =========================================\ntry:\n    model = Model(MODEL_PATH)\n    rec = KaldiRecognizer(model, SAMPLE_RATE)\n    print(\"✅ Vosk (Fast) model loaded\")\nexcept Exception as e:",
        "detail": "wake_fast",
        "documentation": {}
    },
    {
        "label": "BLOCK_SIZE",
        "kind": 5,
        "importPath": "wake_fast",
        "description": "wake_fast",
        "peekOfCode": "BLOCK_SIZE = 1024   # fast\n# =========================================\n# Load Vosk model\n# =========================================\ntry:\n    model = Model(MODEL_PATH)\n    rec = KaldiRecognizer(model, SAMPLE_RATE)\n    print(\"✅ Vosk (Fast) model loaded\")\nexcept Exception as e:\n    print(\"❌ Failed to load Vosk model:\", e)",
        "detail": "wake_fast",
        "documentation": {}
    },
    {
        "label": "tokenize",
        "kind": 2,
        "importPath": "wake_vosk",
        "description": "wake_vosk",
        "peekOfCode": "def tokenize(text):\n    return text.strip().split()\n# =========================================\n# Audio device helper\n# =========================================\ndef get_input_device_index():\n    # IMPORTANT:\n    # If mic does not work, replace None with the correct mic index\n    return None\n# =========================================",
        "detail": "wake_vosk",
        "documentation": {}
    },
    {
        "label": "get_input_device_index",
        "kind": 2,
        "importPath": "wake_vosk",
        "description": "wake_vosk",
        "peekOfCode": "def get_input_device_index():\n    # IMPORTANT:\n    # If mic does not work, replace None with the correct mic index\n    return None\n# =========================================\n# Listen loop\n# =========================================\nimport time  # [NEW]\ndef listen_loop(timeout=None):  # [NEW] timeout support\n    if not rec:",
        "detail": "wake_vosk",
        "documentation": {}
    },
    {
        "label": "listen_loop",
        "kind": 2,
        "importPath": "wake_vosk",
        "description": "wake_vosk",
        "peekOfCode": "def listen_loop(timeout=None):  # [NEW] timeout support\n    if not rec:\n        print(\"❌ Vosk not ready\")\n        return None\n    rec.Reset()\n    try:\n        p = pyaudio.PyAudio()\n        stream = p.open(\n            format=pyaudio.paInt16,\n            channels=1,",
        "detail": "wake_vosk",
        "documentation": {}
    },
    {
        "label": "WAKE_WORDS",
        "kind": 5,
        "importPath": "wake_vosk",
        "description": "wake_vosk",
        "peekOfCode": "WAKE_WORDS = [\"इवा\", \"iva\", \"kira\", \"ava\", \"hyva\", \"hey nova\", \"hey\"]  # check multiple\nMODEL_PATH = \"vosk-model-small-hi-0.22\"\nSAMPLE_RATE = 16000\nBLOCK_SIZE = 4000          # 0.5 sec\nRMS_THRESHOLD = 30         # VERY LOW (important)\nMIN_TOKENS = 1             # allow even 1-word speech\n# =========================================\n# Load Vosk model ONCE\n# =========================================\ntry:",
        "detail": "wake_vosk",
        "documentation": {}
    },
    {
        "label": "MODEL_PATH",
        "kind": 5,
        "importPath": "wake_vosk",
        "description": "wake_vosk",
        "peekOfCode": "MODEL_PATH = \"vosk-model-small-hi-0.22\"\nSAMPLE_RATE = 16000\nBLOCK_SIZE = 4000          # 0.5 sec\nRMS_THRESHOLD = 30         # VERY LOW (important)\nMIN_TOKENS = 1             # allow even 1-word speech\n# =========================================\n# Load Vosk model ONCE\n# =========================================\ntry:\n    model = Model(MODEL_PATH)",
        "detail": "wake_vosk",
        "documentation": {}
    },
    {
        "label": "SAMPLE_RATE",
        "kind": 5,
        "importPath": "wake_vosk",
        "description": "wake_vosk",
        "peekOfCode": "SAMPLE_RATE = 16000\nBLOCK_SIZE = 4000          # 0.5 sec\nRMS_THRESHOLD = 30         # VERY LOW (important)\nMIN_TOKENS = 1             # allow even 1-word speech\n# =========================================\n# Load Vosk model ONCE\n# =========================================\ntry:\n    model = Model(MODEL_PATH)\n    rec = KaldiRecognizer(model, SAMPLE_RATE)",
        "detail": "wake_vosk",
        "documentation": {}
    },
    {
        "label": "BLOCK_SIZE",
        "kind": 5,
        "importPath": "wake_vosk",
        "description": "wake_vosk",
        "peekOfCode": "BLOCK_SIZE = 4000          # 0.5 sec\nRMS_THRESHOLD = 30         # VERY LOW (important)\nMIN_TOKENS = 1             # allow even 1-word speech\n# =========================================\n# Load Vosk model ONCE\n# =========================================\ntry:\n    model = Model(MODEL_PATH)\n    rec = KaldiRecognizer(model, SAMPLE_RATE)\n    rec.SetWords(False)",
        "detail": "wake_vosk",
        "documentation": {}
    },
    {
        "label": "RMS_THRESHOLD",
        "kind": 5,
        "importPath": "wake_vosk",
        "description": "wake_vosk",
        "peekOfCode": "RMS_THRESHOLD = 30         # VERY LOW (important)\nMIN_TOKENS = 1             # allow even 1-word speech\n# =========================================\n# Load Vosk model ONCE\n# =========================================\ntry:\n    model = Model(MODEL_PATH)\n    rec = KaldiRecognizer(model, SAMPLE_RATE)\n    rec.SetWords(False)\n    rec.SetPartialWords(False)",
        "detail": "wake_vosk",
        "documentation": {}
    },
    {
        "label": "MIN_TOKENS",
        "kind": 5,
        "importPath": "wake_vosk",
        "description": "wake_vosk",
        "peekOfCode": "MIN_TOKENS = 1             # allow even 1-word speech\n# =========================================\n# Load Vosk model ONCE\n# =========================================\ntry:\n    model = Model(MODEL_PATH)\n    rec = KaldiRecognizer(model, SAMPLE_RATE)\n    rec.SetWords(False)\n    rec.SetPartialWords(False)\n    print(\"✅ Vosk model loaded\")",
        "detail": "wake_vosk",
        "documentation": {}
    }
]